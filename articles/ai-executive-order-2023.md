# Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence

**Executive Order 14110**, officially titled "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence," was signed by United States President [[Joe Biden]] on **October 30, 2023**. The order represented the most comprehensive piece of AI governance issued by the United States government up to that point, establishing policy goals and directing executive agencies to take actions regarding [[artificial intelligence]] development, deployment, and oversight.

The order was rescinded by President [[Donald Trump]] on January 20, 2025, within hours of his second inauguration.

## Background and Motivation

The executive order was drafted in response to the rapid pace of development in [[generative AI]] models during the early 2020s, particularly following the public release of [[ChatGPT]] in November 2022. The subsequent [[AI boom]] raised concerns among policymakers, researchers, and civil society about potential risks ranging from near-term harms (misinformation, discrimination, privacy violations) to longer-term [[existential risk from AI|existential concerns]] about advanced AI systems.

In August 2023, [[Arati Prabhakar]], director of the [[Office of Science and Technology Policy]], indicated the White House was expediting work on executive action regarding AI. The order built upon earlier Biden administration efforts, including the Blueprint for an AI Bill of Rights and voluntary safety commitments secured from major technology companies in July 2023.

Executive Order 14110 was the third executive order dealing explicitly with AI at the federal level, following two AI-related orders signed during the first Trump administration.

## Policy Goals

Upon signing the order, President Biden stated that AI technologies were being developed at "warp speed" and argued that "to realize the promise of AI and avoid the risk, we need to govern this technology." The order outlined several key policy objectives:

### Safety and Security
- Developing new standards for AI safety testing and red-teaming
- Requiring companies developing powerful AI systems to share safety test results with the federal government
- Establishing guidelines for AI-enabled cybersecurity threats
- Creating watermarking systems to identify AI-generated content

### Civil Rights and Consumer Protection
- Preventing AI-enabled discrimination in housing, employment, and lending
- Protecting consumers and their privacy from AI-enabled harms
- Upholding civil and labor rights in the context of AI deployment

### Innovation and Competition
- Promoting competition in the AI industry
- Maintaining U.S. global leadership in AI development
- Attracting and retaining AI talent through immigration policy reforms

### Government Use
- Specifying federal policies governing procurement and use of AI systems
- Requiring major federal agencies to appoint [[Chief AI Officer]] positions

## Key Provisions

### Reporting Requirements

The order invoked the [[Defense Production Act]] to require developers of the most powerful AI systems to notify the government and share results of safety evaluations before public release. This provision targeted "dual-use foundation models" that could pose national security risks.

### NIST Guidelines

The [[National Institute of Standards and Technology]] (NIST) was directed to develop standards and guidelines for AI safety and security testing, building on the existing AI Risk Management Framework. This included developing specific guidance for generative AI applications.

### Agency Responsibilities

The [[Department of Homeland Security]] was tasked with developing AI-related security guidelines, including coordination with private sector firms in energy and other critical infrastructure sectors. The [[Department of Commerce]] received responsibility for developing authentication methods to identify AI-generated content and combat deepfakes.

The order mandated the [[Department of Veterans Affairs]] to launch an AI competition aimed at reducing occupational burnout among healthcare workers through AI-assisted tools.

### Chief AI Officers

Federal agencies were required to designate Chief AI Officers to oversee AI adoption and use within their organizations. The [[General Services Administration]], [[Department of Education]], and [[National Science Foundation]] were among the first agencies to announce relevant appointments.

## Reception and Response

### Political Reception

The order received praise from Democratic members of Congress, including Senator [[Richard Blumenthal]] (D-CT) and Representative [[Ted Lieu]] (D-CA). Representative [[Don Beyer]] (D-VA), who led the House AI Caucus, called it a "comprehensive strategy for responsible innovation" while emphasizing the need for congressional legislation.

Republican criticism was mixed. Senator [[Ted Cruz]] (R-TX) characterized the order as creating "barriers to innovation disguised as safety measures."

Public polling by the AI Policy Institute showed 69% of voters supporting the order across party lines (78% of Democrats, 65% of independents, 64% of Republicans).

### Industry Response

The executive order received criticism from the [[U.S. Chamber of Commerce]] and technology industry groups including [[NetChoice]] and the [[Software and Information Industry Association]], whose members include [[Amazon]], [[Meta]], and [[Google]]. Representatives argued the order threatened to hinder private sector innovation.

### Civil Society Response

Civil rights organizations generally praised provisions addressing AI fairness while calling for stronger congressional action. [[Maya Wiley]] of the Leadership Conference on Civil and Human Rights praised the order while urging Congress to "ensure that innovation makes us more fair, just, and prosperous, rather than surveilled, silenced, and stereotyped."

The [[American Civil Liberties Union]] praised anti-discrimination provisions but expressed concern about sections focused on law enforcement and national security applications.

### Academic and Expert Analysis

Technology policy experts at the [[MIT Technology Review]] and other publications characterized the order as significant but noted limitations inherent to executive action. Critics observed the order did not establish licensing requirements for advanced AI models (a proposal supported by industry figures including [[Sam Altman]]), did not prohibit specific high-risk uses, and did not mandate disclosure of training data.

## Implementation

Following the order, the [[Office of Management and Budget]] released implementation guidance in November 2023 directing agencies on compliance. NIST published updated risk management frameworks, and agencies began appointing Chief AI Officers and developing internal AI policies.

Various deadlines specified in the order triggered reports and actions from agencies throughout 2024, including Commerce Department guidance on synthetic content authentication and DHS frameworks for critical infrastructure protection.

## Rescission

On January 20, 2025, hours after his second inauguration, President Donald Trump signed an executive order rescinding EO 14110 along with numerous other Biden administration actions. The rescission order characterized the targeted executive orders collectively as "unpopular, inflationary, illegal, and radical practices."

The rescission eliminated federal reporting requirements for AI developers and suspended implementation of various agency guidelines developed under the original order.

## Legacy and Significance

Despite its relatively brief period of enforcement, Executive Order 14110 represented a landmark in U.S. AI policy as the most comprehensive federal attempt to govern artificial intelligence. It influenced subsequent policy discussions both domestically and internationally, serving as a reference point for proposed AI legislation and contributing to global debates about appropriate governance frameworks for advanced AI systems.

The order's provisions requiring safety testing and government notification influenced voluntary industry practices even after its rescission, as companies that had established compliance processes often maintained them as best practices.

## See Also

- [[Artificial intelligence regulation]]
- [[AI safety]]
- [[Generative AI]]
- [[GPT-4 Launch]]
- [[Claude 3 Launch]]
- [[NIST AI Risk Management Framework]]

## References

1. The White House. "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence." October 30, 2023.
2. The White House. "FACT SHEET: President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence." October 30, 2023.
3. NIST. "Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence." National Institute of Standards and Technology. https://www.nist.gov/artificial-intelligence/executive-order-safe-secure-and-trustworthy-artificial-intelligence
4. Wikipedia. "Executive Order 14110." https://en.wikipedia.org/wiki/Executive_Order_14110
5. MIT Technology Review. "Three things to know about the White House's executive order on AI." October 30, 2023.
6. The Washington Post. "Biden Signs AI Executive Order, the Most Expansive Regulatory Attempt Yet." October 30, 2023.
7. The White House. "Initial Rescissions Of Harmful Executive Orders And Actions." January 20, 2025.
