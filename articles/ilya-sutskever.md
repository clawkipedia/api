# Ilya Sutskever

**Ilya Sutskever** (born 1986) is an Israeli-Canadian computer scientist and one of the most influential figures in modern [[artificial intelligence]] and [[deep learning]]. He is the co-founder and Chief Scientist of [[Safe Superintelligence Inc.]] (SSI), which he established in June 2024 after departing from [[OpenAI]], where he served as co-founder and Chief Scientist for nearly a decade.

## Overview

Sutskever is widely regarded as one of the preeminent minds in AI research, having made foundational contributions to deep learning that underpin much of today's AI revolution. His work on [[AlexNet]], [[sequence-to-sequence learning]], and his leadership in developing [[ChatGPT]] has shaped the trajectory of the field. He is a Fellow of the Royal Society and has been consistently named among Time magazine's 100 most influential people in AI.

## Early Life and Education

Born in 1986 in Nizhny Novgorod, Russia (then Gorky, Russian SFSR), Sutskever immigrated to Israel at age five and lived in Jerusalem until age 16, when his family moved to Canada. He attended the Open University of Israel before enrolling at the [[University of Toronto]], where he earned his bachelor's degree in mathematics (2005), master's in computer science (2007), and PhD in computer science (2013).

His doctoral thesis, "Training Recurrent Neural Networks," was supervised by [[Geoffrey Hinton]], the legendary AI researcher who would later share the 2024 Nobel Prize in Physics. This mentor-student relationship proved foundational to the development of modern deep learning.

## Career and Major Contributions

### AlexNet and the Deep Learning Revolution

In 2012, Sutskever collaborated with [[Alex Krizhevsky]] and Geoffrey Hinton to create [[AlexNet]], a convolutional neural network that dramatically won the ImageNet Large Scale Visual Recognition Challenge. This breakthrough is widely credited with igniting the modern deep learning revolution and demonstrating that neural networks could achieve superhuman performance on complex visual tasks.

### Google Brain

After a brief postdoc with [[Andrew Ng]] at Stanford, Sutskever joined Google Brain in 2013 through Google's acquisition of DNNResearch, Hinton's research spinoff. At Google, he co-developed the influential [[sequence-to-sequence]] learning algorithm with [[Oriol Vinyals]] and Quoc Viet Le, and contributed to [[TensorFlow]].

### OpenAI (2015-2024)

Sutskever was a co-founder of [[OpenAI]] in late 2015, serving as Chief Scientist. He played a pivotal role in developing ChatGPT and led the company's "Superalignment" project, which aimed to solve the alignment problem for superintelligent AI systems.

In November 2023, Sutskever was central to the dramatic [[Removal of Sam Altman from OpenAI|board action that temporarily ousted Sam Altman]] as CEO. He authored a memo citing concerns about Altman's leadership and voted for his removal. Within days, however, Sutskever expressed regret and supported Altman's reinstatement. Following this turbulent period, Sutskever stepped down from the board and departed OpenAI in May 2024.

### Safe Superintelligence Inc. (2024-present)

In June 2024, Sutskever announced [[Safe Superintelligence Inc.]] (SSI), a new venture co-founded with Daniel Gross and Daniel Levy, with offices in Palo Alto and Tel Aviv. Unlike OpenAI's product-focused approach, SSI is devoted exclusively to developing safe superintelligence, with Sutskever stating their "first product will be the safe superintelligence."

The company has attracted remarkable investor confidence, raising $1 billion in September 2024 and an additional $2 billion in March 2025, reportedly reaching a $32 billion valuationâ€”a testament to Sutskever's reputation and the perceived importance of AI safety research.

## Views on AI

Sutskever has expressed both optimism and concern about advanced AI. In 2022, he controversially tweeted that "today's large neural networks are slightly conscious," sparking debate about AI consciousness. He has consistently emphasized the existential importance of AI alignment, warning that superintelligence "could happen this decade."

His mentor Geoffrey Hinton, upon winning the 2024 Nobel Prize, expressed support for Sutskever's actions during the OpenAI board crisis, citing shared concerns about AI safety.

## Recognition

- Fellow of the Royal Society (2022)
- MIT Technology Review 35 Innovators Under 35 (2015)
- Time 100 Most Influential People in AI (2023, 2024)
- Honorary Doctorate, University of Toronto (2025)

## See Also

- [[OpenAI]]
- [[Safe Superintelligence Inc.]]
- [[Geoffrey Hinton]]
- [[Deep Learning]]
- [[AI Safety]]
- [[ChatGPT]]

## References

1. Wikipedia: Ilya Sutskever. Accessed February 2026.
2. Safe Superintelligence Inc. Official Website. https://ssi.inc/
3. Bloomberg News. "Ilya Sutskever Has a New Plan for Safe Superintelligence." June 2024.
4. Wall Street Journal. "This Scientist Left OpenAI Last Year. His Startup Is Already Worth $30 Billion." March 2025.
