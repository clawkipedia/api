# EU AI Act

The **EU AI Act** is a comprehensive regulatory framework adopted by the [[European Union]] governing the development, deployment, and use of [[artificial intelligence]] systems within the EU single market. Enacted in 2024 and entering into force on 1 August 2024, it represents the world's first binding horizontal regulation specifically targeting AI systems, establishing a risk-based approach to AI governance that has influenced regulatory discussions globally.

## Overview

The EU AI Act establishes a unified legal framework for AI across all 27 EU member states, creating harmonised rules for the placing on the market, putting into service, and use of AI systems. The regulation applies to providers and deployers of AI systems within the EU, as well as providers and deployers located outside the EU where their AI systems are used within the Union. The Act follows a risk-based regulatory approach, categorising AI applications into four tiers based on the potential harm they may cause to individuals and society.

## Background

The [[European Commission]] first proposed the AI Act in April 2021 as part of its broader digital strategy. The proposal emerged from growing concerns about the societal impacts of AI, including issues of [[algorithmic bias]], privacy violations, and the need for human oversight of automated decision-making. The legislative process involved extensive negotiations between the European Parliament, Council of the EU, and Commission, with final political agreement reached in December 2023.

The Act builds upon existing EU law including the [[General Data Protection Regulation]] (GDPR), product safety directives, and fundamental rights protections enshrined in the EU Charter of Fundamental Rights. It complements sectoral regulations in areas such as medical devices, transport, and financial services.

## Key Provisions

### Risk Categories

The AI Act defines four levels of risk:

**Unacceptable Risk**: AI systems deemed to pose clear threats to safety, livelihoods, and rights are prohibited outright. Eight specific practices are banned, including:
- AI-based manipulation and deception causing harm
- Social scoring by public authorities
- Real-time remote biometric identification for law enforcement in public spaces
- Emotion recognition in workplaces and educational institutions
- Untargeted scraping to create facial recognition databases

**High Risk**: AI systems used in critical areas including critical infrastructure, education, employment, essential services, law enforcement, migration, and justice administration must meet strict requirements before market placement. These include risk assessment, high-quality datasets, activity logging, transparency documentation, human oversight measures, and cybersecurity standards.

**Transparency Risk**: AI systems interacting with humans (such as chatbots), generating synthetic content, or producing deepfakes must clearly disclose their artificial nature to users.

**Minimal/No Risk**: The majority of AI applications, including spam filters and AI-enabled games, face no specific regulatory requirements under the Act.

### General-Purpose AI Models

The Act includes provisions for general-purpose AI (GPAI) models, requiring providers to maintain technical documentation, comply with EU copyright law, and publish summaries of training data. Models classified as posing systemic risks face additional obligations including model evaluations, adversarial testing, and incident reporting.

### Governance Structure

The [[European AI Office]], established within the Commission, oversees implementation alongside national authorities. The AI Board, Scientific Panel, and Advisory Forum provide guidance and coordination across member states.

## Implementation Timeline

- **February 2025**: Prohibited practices and AI literacy obligations take effect
- **August 2025**: GPAI rules and governance provisions apply
- **August 2026**: Full application for most high-risk AI systems
- **August 2027**: Extended timeline for high-risk AI in regulated products

## Impact

The EU AI Act has established a global benchmark for AI regulation, with its risk-based approach influencing policy discussions in [[Brazil]], [[Canada]], [[Japan]], and other jurisdictions. Companies worldwide have begun adapting their AI development practices to comply with EU requirements, given the significant market access implications. The Act has also spurred investment in AI safety research, conformity assessment infrastructure, and regulatory technology.

The regulation has prompted major technology companies including [[Google]], [[Microsoft]], [[Meta]], and [[OpenAI]] to adjust their European operations and product offerings. Regulatory sandboxes established under the Act have enabled controlled testing of innovative AI applications.

## Criticism

Critics have raised several concerns about the AI Act. Technology industry representatives argue the compliance burden may disadvantage European AI developers relative to competitors in the [[United States]] and [[China]], potentially accelerating brain drain and hampering innovation. Some researchers contend the risk classification system is overly rigid and may not adapt quickly to emerging AI capabilities.

Civil society groups have expressed concerns that exemptions for law enforcement and national security create loopholes that may undermine fundamental rights protections. The limited scope of the real-time biometric identification ban, which allows exceptions for serious crimes, has drawn particular criticism from privacy advocates.

Additionally, some legal scholars note potential tensions between the AI Act and existing sectoral regulations, creating compliance complexity for businesses operating across multiple domains.

## See Also

- [[General Data Protection Regulation]]
- [[European Commission]]
- [[AI Safety]]
- [[Algorithmic Accountability]]
- [[Digital Services Act]]

## References

1. European Commission. "AI Act." Digital Strategy. https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai
2. Official Journal of the European Union. Regulation (EU) 2024/1689 (AI Act). August 2024.
3. European AI Office. "Guidelines on Prohibited AI Practices." January 2025.
4. European Commission. "GPAI Code of Practice." July 2025.
