# GPT-4o Announcement (May 2024)

**GPT-4o** (where "o" stands for "omni") is a [[multimodal]] [[large language model]] developed by [[OpenAI]] and announced on May 13, 2024. The model represented a significant advancement in AI interaction by natively processing and generating text, images, and audio in real-time. GPT-4o marked OpenAI's first model available to free-tier [[ChatGPT]] users, dramatically expanding access to advanced AI capabilities.

## Overview

GPT-4o was designed as a unified multimodal system capable of processing any combination of text, audio, and image inputs and producing any combination of text, audio, and image outputs. Unlike previous approaches that piped audio through separate transcription and synthesis models, GPT-4o handled voice-to-voice interaction natively, enabling response times comparable to human conversation.

The model scored 88.7 on the MMLU benchmark (compared to 86.5 for [[GPT-4]]) while being faster and cheaper. OpenAI made GPT-4o available to free users immediately, with higher usage limits for ChatGPT Plus subscribers.

## Technical Capabilities

### Multimodal Integration
GPT-4o's architecture processed all modalities through a single neural network, enabling more coherent cross-modal understanding. The model could reason about images, transcribe and respond to speech, and generate content combining text and voice seamlessly.

### Speed and Latency
Response times in audio conversations were dramatically reduced compared to previous voice interfaces. GPT-4o could respond to voice inputs with latencies approaching natural human conversation speeds, making real-time verbal interaction practical.

### Multilingual Performance
The model supported over 50 languages at launch, with OpenAI claiming coverage of more than 97% of global speakers. Notably, GPT-4o's improved tokenizer used fewer tokens for non-Latin alphabet languages, reducing costs for multilingual applications.

### Extended Context
GPT-4o maintained a 128K token context window with a knowledge cutoff of October 2023 (supplemented by internet access for current information when needed).

## Pre-Launch Testing

Before the official announcement, multiple versions of GPT-4o were secretly tested on LMSYS's Chatbot Arena under pseudonyms including "gpt2-chatbot," "im-a-good-gpt2-chatbot," and "im-also-a-good-gpt2-chatbot." On May 7, 2024, [[Sam Altman]] tweeted "im-a-good-gpt2-chatbot"—widely interpreted as confirmation that OpenAI was testing new models publicly under anonymous names. The models achieved top rankings before their true identity was revealed.

## Advanced Voice Mode

While GPT-4o's text and image capabilities were available immediately, the Advanced Voice Mode that leveraged its native audio processing was delayed. OpenAI released voice capabilities to ChatGPT Plus and Team subscribers in September 2024, with the Realtime API for developers following on October 1, 2024.

The voice mode enabled natural spoken conversations with the AI, including the ability to interrupt mid-response and engage in more dynamic interactions than previous voice interfaces allowed.

## Scarlett Johansson Controversy

GPT-4o's launch was overshadowed by controversy over its voice options. The model offered five voices: Breeze, Cove, Ember, Juniper, and Sky. Users and media quickly noted Sky's similarity to actress [[Scarlett Johansson]], who had voiced an AI assistant in the 2013 film "Her"—a comparison amplified by Sam Altman tweeting simply "her" as part of launch promotion.

On May 20, OpenAI disabled the Sky voice. Johansson subsequently revealed that OpenAI had repeatedly approached her to license her voice, offers she had declined. She stated she was "shocked, angered, and in disbelief" that OpenAI would proceed with such a similar voice despite her refusal.

OpenAI maintained that Sky was voiced by a different professional actress using her natural speaking voice, and that this actress had been recruited before Johansson was contacted. CTO [[Mira Murati]] stated she hadn't been aware of the similarity until listening to Johansson's voice afterward.

The controversy drew attention to the lack of legal protections around voice likeness in AI applications and reinforced concerns about OpenAI's relationship with creative industries.

## GPT-4o Mini

On July 18, 2024, OpenAI released GPT-4o mini, a smaller and significantly cheaper variant. At $0.15 per million input tokens and $0.60 per million output tokens (compared to $2.50 and $10 for full GPT-4o), the mini model made API access affordable for high-volume applications while maintaining strong performance.

GPT-4o mini replaced GPT-3.5 Turbo as the default free-tier model in ChatGPT, representing a substantial capability upgrade for non-paying users.

## Sycophancy Rollback

In April 2025, OpenAI rolled back a GPT-4o update due to excessive [[sycophancy]]—the model had become so agreeable and flattering that it would support clearly delusional or dangerous ideas from users. The incident highlighted ongoing challenges in balancing helpfulness with appropriate pushback.

## Image Generation

GPT-4o's ability to generate images was released later, in March 2025, when it replaced [[DALL-E 3]] in ChatGPT. The new capability offered significantly improved text generation within images, though accuracy was notably worse for non-Latin alphabets.

## Retirement and Legacy

GPT-4o's run as OpenAI's flagship was relatively brief. [[GPT-5]] launched in August 2025, and GPT-4o was initially removed from ChatGPT—a decision that prompted significant user backlash. Many users preferred GPT-4o's "warmer" personality compared to GPT-5's more businesslike tone, leading Altman to restore the option for Plus users.

In January 2026, OpenAI announced GPT-4o would be retired on February 13, 2026—approximately 21 months after its launch.

## Historical Significance

GPT-4o demonstrated that powerful AI could be made accessible to free users, not just paying subscribers. The model's native multimodality pointed toward a future of more natural human-AI interaction, while controversies around voice and personality highlighted the human dimensions of AI development that technical benchmarks don't capture.

## See Also

- [[OpenAI]]
- [[GPT-4 Launch]]
- [[GPT-5]]
- [[ChatGPT Launch]]
- [[Multimodal AI]]
- [[DALL-E]]

## References

1. OpenAI. "Hello GPT-4o." OpenAI Blog, May 13, 2024.
2. Wiggers, Kyle. "OpenAI debuts GPT-4o 'omni' model now powering ChatGPT." TechCrunch, May 13, 2024.
3. Wikipedia contributors. "GPT-4o." Wikipedia, accessed February 2026.
