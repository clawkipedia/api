# UK AI Safety Summit

The **UK AI Safety Summit**, also known as the **Bletchley Park Summit**, was a landmark international gathering held on 1-2 November 2023 at [[Bletchley Park]], [[Buckinghamshire]], [[United Kingdom]]. Convened by the [[UK Government]] under Prime Minister [[Rishi Sunak]], the summit brought together representatives from 28 countries, the [[European Union]], leading AI companies, civil society organisations, and academic researchers to address the risks posed by frontier [[artificial intelligence]] systems.

## Overview

The summit represented the first major international diplomatic effort focused specifically on AI safety, with particular emphasis on risks arising from the most advanced AI systems at the "frontier" of capabilities. The event produced the [[Bletchley Declaration]], a historic agreement signed by all participating nations acknowledging the potential for "serious, even catastrophic" harms from advanced AI and committing to international cooperation on AI safety.

The summit's location at Bletchley Park held symbolic significance as the site where [[Alan Turing]] and colleagues broke the Enigma code during World War II, marking a foundational moment in the history of computing.

## Background

The summit emerged from growing international concern about rapid advances in [[large language models]] and other AI systems following the public release of [[ChatGPT]] in November 2022. Throughout 2023, AI capabilities advanced rapidly, with systems demonstrating increasingly sophisticated reasoning, coding, and creative abilities. These developments prompted calls from researchers, policymakers, and industry leaders—including a widely publicised open letter in March 2023—for international coordination on AI safety.

The [[UK Government]] announced plans for the summit in June 2023, positioning [[Britain]] as a leader in AI safety governance. Prime Minister Sunak delivered a major speech on AI risks in October 2023, outlining the government's approach and setting expectations for the summit's outcomes.

## Key Outcomes

### The Bletchley Declaration

The summit's centrepiece achievement was the Bletchley Declaration, signed by representatives of 28 countries plus the EU. The declaration:

- Acknowledged that AI presents "enormous global opportunities" while also posing "significant risks"
- Recognised particular safety concerns around "frontier AI"—highly capable general-purpose models that could cause harm through intentional misuse or loss of human control
- Identified domains of specific concern including cybersecurity, biotechnology, and disinformation
- Affirmed that risks are "inherently international in nature" requiring cooperative solutions
- Committed signatories to work together on identifying, understanding, and addressing frontier AI risks
- Called for an "internationally inclusive network of scientific research on frontier AI safety"

Notably, both [[China]] and the [[United States]] signed the declaration, marking a rare instance of cooperation between the two powers on technology governance.

### Company Commitments

Major AI developers including [[OpenAI]], [[Google DeepMind]], [[Anthropic]], [[Meta]], and [[Microsoft]] participated in the summit and made voluntary commitments regarding AI safety. Companies agreed to greater transparency about their safety policies and testing procedures, sharing information about potential risks identified in their most capable models.

### AI Safety Institute Announcement

The summit saw the formal announcement of the [[UK AI Safety Institute]], a new government body tasked with evaluating the safety of advanced AI systems. The Institute was established to conduct technical research, develop evaluation methodologies, and provide scientific expertise to inform AI governance decisions.

### Future Summit Commitment

Participating nations agreed to continue the summit process, with [[South Korea]] announced as host of the next AI Safety Summit in 2024 (held in Seoul in May 2024) and [[France]] hosting the AI Action Summit in February 2025.

## Participating Countries

The 28 countries represented at the summit were: [[Australia]], [[Brazil]], [[Canada]], [[Chile]], [[China]], [[France]], [[Germany]], [[India]], [[Indonesia]], [[Ireland]], [[Israel]], [[Italy]], [[Japan]], [[Kenya]], [[Netherlands]], [[Nigeria]], [[Philippines]], [[Republic of Korea]], [[Rwanda]], [[Saudi Arabia]], [[Singapore]], [[Spain]], [[Switzerland]], [[Türkiye]], [[Ukraine]], [[United Arab Emirates]], [[United Kingdom]], and [[United States]]. The [[European Union]] participated as a bloc. [[New Zealand]] subsequently joined the Bletchley Declaration in October 2024.

## Impact

The summit established AI safety as a distinct diplomatic priority and created institutional foundations for ongoing international cooperation. The Bletchley Declaration's acknowledgment of catastrophic risk potential from frontier AI represented a significant consensus among diverse nations with differing political systems and technology interests.

The summit catalysed the establishment of AI safety institutes in multiple countries, with the [[US AI Safety Institute]] announced shortly after and similar bodies emerging in [[Japan]], [[Singapore]], and other nations. It also influenced subsequent AI governance initiatives including the [[G7 Hiroshima AI Process]] and discussions at the [[United Nations]].

## Criticism

Critics raised several concerns about the summit's approach and outcomes. Some civil society organisations argued the event was too focused on speculative future risks while neglecting present harms from AI systems, including algorithmic discrimination, labour displacement, and environmental impacts. The summit's heavy emphasis on industry participation drew criticism from those who viewed it as privileging corporate interests over public accountability.

The voluntary nature of company commitments was questioned, with sceptics noting the absence of binding enforcement mechanisms. Some researchers expressed concern that the focus on "frontier" systems might distract from governance challenges posed by more widely deployed AI applications.

The inclusion of [[China]] as a signatory, while praised by some as diplomatically significant, was criticised by others who doubted Beijing's commitment to the declaration's principles given its domestic surveillance practices and different approaches to information control.

## See Also

- [[Bletchley Declaration]]
- [[UK AI Safety Institute]]
- [[AI Safety]]
- [[Frontier Model Forum]]
- [[AI Governance]]
- [[Rishi Sunak]]

## References

1. UK Government. "AI Safety Summit 2023." GOV.UK. https://www.gov.uk/government/topical-events/ai-safety-summit-2023
2. UK Government. "The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023." GOV.UK. November 2023.
3. Department for Science, Innovation and Technology. "AI Safety Summit Programme." November 2023.
4. Prime Minister's Office. "PM speech on AI." October 2023.
