# AutoGen

**AutoGen** is an open-source framework developed by [[Microsoft Research]] for building [[multi-agent systems]] powered by [[large language models]]. First released in September 2023, AutoGen enables the creation of applications where multiple AI agents engage in conversations to collaboratively solve complex tasks. The framework has gained prominence for its flexible conversation patterns and strong support for human-AI collaboration.

## Overview

AutoGen introduces a conversation-centric paradigm for multi-agent AI, where agents communicate through natural language dialogue to coordinate their activities. Unlike frameworks that emphasize rigid workflows, AutoGen treats multi-agent interaction as a series of conversations that can be dynamically shaped by participants, including human users who can intervene at any point.

The framework emerged from Microsoft's research into LLM-based agents and reflects lessons learned from earlier projects like [[FLAML]] (Fast and Lightweight AutoML). AutoGen emphasizes customizability, allowing developers to define agents with varying capabilitiesâ€”from fully autonomous LLM-powered reasoners to simple scripted responders to human proxies that request user input.

Microsoft has positioned AutoGen as part of its broader AI development ecosystem, complementing tools like [[Semantic Kernel]] and [[Azure AI]] services while maintaining its open-source, framework-agnostic nature.

## Features

AutoGen provides extensive capabilities for multi-agent development:

- **Conversable Agents**: Base abstraction for agents that can send and receive messages, with customizable response generation
- **AssistantAgent**: Pre-configured agent powered by LLMs for general-purpose reasoning and task execution
- **UserProxyAgent**: Agent that can execute code and solicit human input, bridging AI and human participants
- **Group Chat**: Infrastructure for multi-agent conversations with configurable speaker selection strategies
- **Code Execution**: Built-in sandboxed environments for running generated code safely
- **Function Calling**: Native support for LLM function calling, enabling agents to invoke tools
- **Human-in-the-Loop**: Flexible mechanisms for human oversight, from full autonomy to approval-required execution
- **Teachability**: Agents can learn from conversations and persist knowledge across sessions
- **Multimodal Support**: Capability to process and generate responses involving images and other media

## Architecture

AutoGen's architecture centers on the concept of conversable agents and their interactions:

**Agents** are the fundamental building blocks. Each agent implements a conversation interface with methods for generating replies, processing messages, and managing state. The `ConversableAgent` base class provides core functionality that specialized agents extend.

**Conversations** occur between agents through message passing. Two-agent conversations follow a simple request-response pattern, while group chats enable complex multi-party interactions with customizable turn-taking policies.

**Group Chat Manager** orchestrates multi-agent conversations by selecting which agent speaks next. Selection strategies include round-robin, random, and LLM-based selection where a model decides the most appropriate next speaker.

**Code Execution** is handled by executor components that can run code in local processes, Docker containers, or cloud-based sandboxes. The `UserProxyAgent` typically handles code execution, running code generated by `AssistantAgent` and returning results.

**AutoGen Studio** provides a visual interface for building and testing multi-agent workflows without writing code, lowering the barrier to experimentation.

The framework supports multiple LLM backends including [[OpenAI]], [[Azure OpenAI]], and local models, with a unified configuration system for managing model access.

## Use Cases

AutoGen excels in collaborative problem-solving scenarios:

- **Software Development**: Agent teams that architect, implement, review, and test code through conversation
- **Research**: Collaborative literature review and analysis where agents contribute different perspectives
- **Data Science**: Analyst agents that explore data while executor agents run statistical computations
- **Education**: Tutoring systems where teacher and student agents engage in Socratic dialogue
- **Game Development**: NPCs with distinct personalities engaging in dynamic conversations
- **Decision Support**: Advisory systems where multiple expert agents debate recommendations
- **Content Creation**: Writing teams with researcher, writer, editor, and fact-checker agents

## See Also

- [[LangChain]]
- [[CrewAI]]
- [[AutoGPT]]
- [[LlamaIndex]]
- [[Semantic Kernel]]
- [[Multi-Agent Systems]]

## References

1. Wu, Q., et al. (2023). "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation." Microsoft Research. arXiv preprint.
2. Microsoft. AutoGen Documentation. https://microsoft.github.io/autogen/
3. Dibia, V. (2023). "AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems." Microsoft Research Blog.
4. Microsoft Research. (2023). "AutoGen: Multi-Agent Conversation Framework." GitHub Repository.
