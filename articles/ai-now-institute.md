# AI Now Institute

The **AI Now Institute** is an American research organization studying the social implications of [[artificial intelligence]] and the concentration of power in the technology industry. Founded in 2017 and originally affiliated with New York University, AI Now conducts policy research, publishes influential annual reports, and advocates for accountability and transparency in AI systems.

## Overview

Unlike organizations focused primarily on technical [[ai-safety]] or existential risk, AI Now centers its work on present-day harms from AI deployment—algorithmic bias, surveillance, labor impacts, and the concentration of power among a small number of technology companies. The institute takes a "social systems first" approach, treating AI deployment problems as fundamentally social and political rather than purely technical.

AI Now has been particularly influential in advocating for algorithmic accountability in government decision-making, opposing opaque "black box" systems in criminal justice, healthcare, welfare, and education.

## History

### Origins

AI Now grew out of a 2016 symposium organized by the Obama-era White House Office of Science and Technology Policy. The event was led by Meredith Whittaker, founder of Google's Open Research Group, and Kate Crawford, a principal researcher at Microsoft Research. It focused on near-term AI implications across inequality, labor, ethics, and healthcare.

### Founding

In November 2017, AI Now held a second symposium on AI and social issues and publicly launched as a formal research institute in partnership with New York University. It was reportedly the first university research institute focused specifically on AI's social implications, and the first AI institute founded and led by women.

### Independence

AI Now has since become a fully independent institute, no longer formally affiliated with NYU. Its executive director is Amba Kak.

## Key Figures

**Meredith Whittaker** (Co-founder): Former Google researcher who led the Open Research Group. Organized the 2018 Google walkout protesting the company's handling of sexual harassment. Now serves as President of Signal Foundation.

**Kate Crawford** (Co-founder): Senior Principal Researcher at Microsoft Research and author of *Atlas of AI* (2021). Research focuses on social and political implications of AI and data systems.

**Amba Kak** (Executive Director): Previously worked on technology and human rights policy. Leads AI Now's current research and advocacy programs.

In 2021-22, AI Now leadership served as Senior Advisors on AI to FTC Chair Lina Khan, directly influencing antitrust and competition policy regarding technology companies.

## Research and Publications

### Annual Reports

AI Now publishes annual "Landscape Reports" examining the state of AI and its integration into society. Key reports include:

**2017 Report**: Stated that "current framings of AI ethics are failing" and provided ten strategic recommendations, including pre-release trials of AI systems and increased research into bias. Called for ending "black box" systems in core social domains.

**2023 Report**: Argued that meaningful reform must address concentrated power in the tech industry, focusing on market dominance and anti-competitive practices rather than purely technical fixes.

**2025 Artificial Power Report**: Maps the AI market, interrogates the industry's key sources of power, and provides strategies to "reclaim public agency over the future of AI." Examines issues including potential AI industry bailouts with public funds.

### Algorithmic Impact Assessments

In April 2018, AI Now released a framework for Algorithmic Impact Assessments (AIAs)—a mechanism for governments to evaluate AI use in public agencies. Similar to environmental impact assessments, AIAs would require public disclosure and external expert review of AI systems, allowing vetting for biased outcomes, skewed training data, or other issues.

This framework has influenced government approaches to AI accountability and appeared in various policy proposals.

## Focus Areas

### Algorithmic Accountability

AI Now advocates for transparency in algorithmic decision-making, particularly in government contexts like criminal justice, social services, and employment. The institute opposes deployment of opaque systems that affect people's lives without meaningful explanation or recourse.

### Labor and Economic Impacts

Research examines how AI affects workers—not just through automation and job displacement, but through algorithmic management, surveillance, and changing power dynamics between employers and employees.

### Concentration of Power

A central theme in recent AI Now work is that the AI industry's problems stem from excessive concentration among a small number of companies. The 2023 and 2025 reports argue that technical solutions to bias or safety are insufficient without addressing underlying market structure and power dynamics.

### Surveillance and Civil Liberties

AI Now has partnered with the ACLU and other civil liberties organizations to address AI-enabled surveillance, facial recognition, and biometric data collection.

## Partnerships

AI Now has collaborated with numerous organizations including:
- Distributed AI Research Institute (DAIR), founded by Timnit Gebru
- Data & Society
- Ada Lovelace Institute
- Partnership on AI
- American Civil Liberties Union (ACLU)

## Current State (2025-2026)

AI Now continues publishing research and commentary on AI industry developments. Recent work has examined generative AI's effects on the labor market, potential government bailouts of AI companies facing market corrections, and the implications of major antitrust cases against technology companies.

The organization's perspective—emphasizing present harms and power concentration rather than speculative future risks—represents an important strand of AI criticism that sometimes clashes with the existential risk focus of organizations like the [[future-of-life-institute]] or [[center-for-ai-safety]].

## See Also

- [[ai-safety]]
- [[ai-governance]]
- [[interpretability]]
- [[algorithmic-bias]]

## References

1. Wikipedia. "AI Now Institute." Accessed February 2026.
2. AI Now Institute. "About Us." ainowinstitute.org. Accessed February 2026.
3. AI Now Institute. "Artificial Power: 2025 Landscape Report." June 2025.
4. Crawford, Kate. *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. Yale University Press, 2021.
