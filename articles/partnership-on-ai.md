# Partnership on AI

**Partnership on Artificial Intelligence to Benefit People and Society**, commonly known as **Partnership on AI** (PAI), is a nonprofit coalition committed to the responsible use of [[artificial intelligence]]. Founded in September 2016 by major technology companies, PAI brings together organizations from industry, academia, and civil society to develop best practices, conduct research, and promote ethical AI development and deployment.

## Overview

Partnership on AI was created to address the societal implications of artificial intelligence through multi-stakeholder collaboration. As of 2024, PAI includes 126 partner organizations from academia, civil society, and industry based in 16 countries.

The organization operates through five programs addressing key AI challenges:
1. AI and Media Integrity
2. AI, Work, and the Economy
3. Justice, Transparency, and Accountability
4. Inclusive Research and Design
5. Security for AI

Rebecca Finlay has served as CEO since October 26, 2021.

## History

### Founding (2016)

Partnership on AI was publicly announced on September 28, 2016, with founding members:
- [[Amazon]]
- [[Facebook]] (now [[Meta Platforms]])
- [[Google]]
- [[DeepMind]]
- [[Microsoft]]
- [[IBM]]

Initial leadership included interim co-chairs [[Eric Horvitz]] of [[Microsoft Research]] and [[Mustafa Suleyman]] of DeepMind.

### Early Growth (2017-2018)

In January 2017, [[Apple]]'s head of advanced development for [[Siri]], [[Tom Gruber]], joined PAI's board.

In October 2017, [[Terah Lyons]] became PAI's founding executive director, bringing expertise in technology governance from her role as Policy Advisor to U.S. Chief Technology Officer [[Megan Smith]].

In October 2018, [[Baidu]] became the first Chinese firm to join the Partnership.

### Recent Developments (2020-Present)

In November 2020, PAI announced the **AI Incident Database (AIID)**, a tool for identifying, assessing, managing, and communicating AI risk and harm. The AIID transitioned to an independent nonprofit in 2022.

In August 2021, PAI submitted a response to the [[National Institute of Standards and Technology]] (NIST) regarding AI risk management, highlighting projects including:
- Safety Critical AI report on responsible publication
- ABOUT ML project on machine learning documentation
- AI Incident Database
- SafeLife AI learning environment

In February 2023, PAI launched a framework for ethical synthetic media development, with partners including [[Adobe]], [[BBC]], CBC/Radio-Canada, [[Bumble]], [[OpenAI]], [[TikTok]], WITNESS, Synthesia, D-ID, and Respeecher.

## Programs and Initiatives

### AI and Media Integrity

This program establishes best practices ensuring AI's positive influence on the global information ecosystem while mitigating risks of harmful content and amplified negative narratives.

### AI, Labor, and the Economy

A collaborative platform uniting economists, worker representatives, and partners to address how AI can contribute to an inclusive economic future. In June 2023, PAI released "Guidelines for AI and Shared Prosperity," outlining responsible AI use across various stages for organizations, policymakers, and labor entities.

### Fairness, Transparency, and Accountability

This program explores intersections between AI and fundamental human values, establishing guidelines for algorithmic equity, explainability, and responsibility.

### Inclusive Research and Design

Empowers communities by providing guidelines on co-creating AI solutions, fostering inclusivity throughout research and design processes.

### Safety Critical AI

Addresses AI deployment in critical sectors including medicine, finance, transportation, and social media. Initiatives include:
- AI Incident Database
- Norms for responsible publication
- SafeLife AI learning environment
- Guidance for Safe Foundation Model Deployment

## Major Projects

### AI Incident Database

The AIID indexes the collective history of harms or near-harms from AI deployment, serving as a resource for understanding and mitigating AI risks.

### Synthetic Media Framework

Developed with multiple partners to guide ethical creation and use of AI-generated synthetic media, emphasizing transparency, creativity, and safety.

### Explainable AI Workshop

PAI has hosted workshops focused on "explainable artificial intelligence" (XAI), bringing together experts to discuss deployment of interpretable AI systems.

### 2023 Policy Forum

Held in London, this event gathered diverse stakeholders to explore AI policy trends globally. PAI unveiled "Guidance for Safe Foundation Model Deployment" for public feedback.

## Governance

### Board of Directors (as of December 2025)

- **Jerremy Holland** (Board Chair) - [[Apple]]
- **Jatin Aythora** (Board Vice-chair) - [[BBC Research & Development]]
- Esha Bhandari - [[ACLU]]
- Christina Colclough - The Why Not Lab
- Natasha Crampton - [[Microsoft]]
- Angela Kane - [[Vienna Center for Disarmament and Non-Proliferation]]
- Helen King - [[Google DeepMind]]
- [[Vukosi Marivate]] - University of Pretoria
- Lori McGlinchey - [[Ford Foundation]]
- Lama Nachman
- Premkumar Natarjan - [[Capital One]]
- Rohit Prasad - [[Amazon]]
- Rob Sherman - [[Meta Platforms]]
- Brittany Smith - [[OpenAI]]
- Martin Tisn√© - Current AI
- Nicol Turner Lee - [[Brookings Institution]]
- Suresh Venkatasubramanian - [[Brown University]]

## Criticisms and Departures

In October 2020, [[Access Now]] announced its resignation from PAI in a public letter, stating:

- An increasingly smaller role for civil society within PAI
- PAI had not influenced member companies to respond to or consult with civil society systematically
- Disagreement with PAI's approach to AI ethics and risk assessment
- Advocacy for outright bans on technologies incompatible with human rights, such as facial recognition enabling mass surveillance

The departure highlighted tensions between industry-led governance and civil society perspectives on AI ethics.

## Impact

PAI has contributed to AI governance through:

- Development of industry best practices
- Multi-stakeholder dialogue on AI ethics
- Research and documentation resources
- Policy engagement and guidance
- International collaboration on AI challenges

The organization represents an attempt at industry self-regulation, though critics question whether such coalitions can effectively hold powerful technology companies accountable.

## See Also

- [[AI Ethics]]
- [[AI Governance]]
- [[Responsible AI]]
- [[AI Safety]]
- [[Artificial Intelligence]]

## References

1. Partnership on AI official website. partnershiponai.org
2. Wikipedia: Partnership on AI. Accessed February 2026.
3. PAI publications and announcements.
